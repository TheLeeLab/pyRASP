{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc18c59f-eecd-4d0b-a648-7c6c3190769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src import RASPRoutines\n",
    "\n",
    "RASP = RASPRoutines.RASP_Routines()\n",
    "import pandas as pd\n",
    "from src import AnalysisFunctions\n",
    "\n",
    "A_F = AnalysisFunctions.Analysis_Functions()\n",
    "from src import IOFunctions\n",
    "\n",
    "from src import Image_Analysis_Functions\n",
    "\n",
    "IA_F = Image_Analysis_Functions.ImageAnalysis_Functions()\n",
    "\n",
    "from src import CoincidenceFunctions\n",
    "\n",
    "C_F = CoincidenceFunctions.Coincidence_Functions()\n",
    "\n",
    "from src import HelperFunctions\n",
    "H_F = HelperFunctions.Helper_Functions()\n",
    "\n",
    "IO = IOFunctions.IO_Functions()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from src import PlottingFunctions\n",
    "\n",
    "plotter = PlottingFunctions.Plotter()\n",
    "\n",
    "import polars as pl\n",
    "from scipy.signal import fftconvolve, convolve\n",
    "from scipy.ndimage import binary_opening, binary_closing, binary_fill_holes\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73811802-b3ce-4a9e-a024-fc49bd30e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    filtered_image_old,\n",
    "    gradient_x_old,\n",
    "    gradient_y_old,\n",
    "    focus_score_old,\n",
    "    concentration_factor_old,\n",
    ") = IA_F.calculate_gradient_field(cell_mask_raw, k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16110a3-7325-4612-be05-5b049b48eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (1200, 1200)\n",
    "potential_indices = np.prod(image_size)\n",
    "spotperc = 0.001\n",
    "maskperc = 0.25\n",
    "\n",
    "spot_indices = np.unique(np.random.randint(low=0, high=potential_indices, size=int(potential_indices*spotperc)))\n",
    "spot_2_indices = np.unique(np.random.randint(low=0, high=potential_indices, size=int(potential_indices*spotperc)))\n",
    "mask_indices = np.arange(int(potential_indices*maskperc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb85274a-1012-4f96-8a8f-be257c0ab445",
   "metadata": {},
   "outputs": [],
   "source": [
    "        n_iter = 100\n",
    "        coincidence = np.zeros(n_iter)\n",
    "        chance_coincidence = np.zeros(n_iter)\n",
    "        image_size = (1000, 1000)\n",
    "        potential_indices = np.prod(image_size)\n",
    "        lo_perc = 0.0001\n",
    "        n_largeobjects = int(potential_indices*lo_perc)\n",
    "        mask_percentage = 0.25\n",
    "        for i in np.arange(n_iter):\n",
    "            lo_indices = C_F._apply_blur(np.random.randint(low=0, high=int(potential_indices), size=n_largeobjects), image_size, 3)\n",
    "            lo_indices = lo_indices.reshape(n_largeobjects, int(len(lo_indices)/n_largeobjects)).tolist()\n",
    "            mask_indices = np.arange(int(potential_indices*mask_percentage))\n",
    "            coincidence[i], chance_coincidence[i], _, _ =  C_F.calculate_coincidence(spot_indices=None, largeobj_indices=lo_indices, n_largeobjs=n_largeobjects, mask_indices=mask_indices, image_size=image_size, analysis_type=\"largeobj\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28dfdd-7bd9-437b-9655-e5a1c424f4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "        percentages = np.arange(0, 1, 0.01)\n",
    "        image_size = (1000, 1000)\n",
    "        potential_indices = np.prod(image_size)\n",
    "        mask_fill = np.zeros_like(percentages)\n",
    "        for i, p in enumerate(percentages):\n",
    "            mask_indices = np.arange(int(potential_indices * p))\n",
    "            mask_fill[i] = C_F.calculate_mask_fill(mask_indices, image_size)\n",
    "            assert mask_fill[i] == pytest.approx(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a6f13-2644-4d95-ad57-2f1e5667efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coincidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf12f35-74cc-4a8b-84e6-c909dabb526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "        assert np.mean(coincidence) == pytest.approx(0.25, abs=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fff9d4b-2007-4947-8109-3c2a827bbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(olig_cell_ratio, bins=np.histogram_bin_edges(olig_cell_ratio, bins='fd'));\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63409ac-b49d-496f-8e57-c54787c9dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "        from copy import copy\n",
    "        image_size = (1000, 1000)\n",
    "        potential_indices = np.prod(image_size)\n",
    "        spot_percentage = 0.01\n",
    "        spot_indices = np.unique(np.random.randint(low=0, high=potential_indices, size=int(potential_indices*spot_percentage)))\n",
    "        second_spot_indices = copy(spot_indices)\n",
    "        coincidence_1, chance_coincidence_1, coincidence_2, chance_coincidence_2, _, _ =  C_F.calculate_coincidence(spot_indices=spot_indices, mask_indices=None, image_size=image_size, second_spot_indices=second_spot_indices, blur_degree=0, analysis_type=\"spot_to_spot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c05c0-2cce-4ed7-ab8f-3e48028ea50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coincidence_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71357be-6eac-4bf0-916d-2e4797b16ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e53c5e-a8c6-4d8d-9eef-1e8269f667dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.mean(coincidence) == pytest.approx(0.25, abs=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf89b4-5a5b-4402-86aa-44d00aed779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        columns = ['sum_intensity_in_photons', 'z', 'image_filename']\n",
    "        z_planes = np.arange(1, 26)\n",
    "        n_spots = np.random.randint(low=0, high=1000, size=len(z_planes))\n",
    "        filename = '0'.zfill(4)\n",
    "        data = None\n",
    "        for i, z in enumerate(z_planes):\n",
    "            sum_intensity_in_photons = np.ones(n_spots[i])\n",
    "            z_data = np.full_like(sum_intensity_in_photons, z)\n",
    "            image_filename = np.full(len(sum_intensity_in_photons), filename)\n",
    "            if data is not None:\n",
    "                data = np.hstack([data, np.vstack([sum_intensity_in_photons, z_data, image_filename])])\n",
    "            else:\n",
    "                data = np.vstack([sum_intensity_in_photons, z_data, image_filename])\n",
    "        database = pl.DataFrame(data=data, schema=columns)\n",
    "        for i, column in enumerate(columns[:-1]):\n",
    "            database = database.replace_column(\n",
    "                i, pl.Series(column, np.array(database[column].to_numpy(), dtype=\"float\"))\n",
    "            )\n",
    "        spot_numbers = A_F.count_spots(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43bd1a-b868-486c-9536-f6174b758f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(n_spots == spot_numbers['n_spots'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a9fed1-f893-46d7-92f7-471fc247b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "        n_spots = np.full_like(z_planes, 500)\n",
    "        data = None\n",
    "        for i, z in enumerate(z_planes):\n",
    "            sum_intensity_in_photons = np.hstack([np.full(250, 1), np.full(250, 2)])\n",
    "            z_data = np.full_like(sum_intensity_in_photons, z)\n",
    "            image_filename = np.full(len(sum_intensity_in_photons), filename)\n",
    "            if data is not None:\n",
    "                data = np.hstack([data, np.vstack([sum_intensity_in_photons, z_data, image_filename])])\n",
    "            else:\n",
    "                data = np.vstack([sum_intensity_in_photons, z_data, image_filename])\n",
    "        database = pl.DataFrame(data=data, schema=columns)\n",
    "        for i, column in enumerate(columns[:-1]):\n",
    "            database = database.replace_column(\n",
    "                i, pl.Series(column, np.array(database[column].to_numpy(), dtype=\"float\"))\n",
    "            )\n",
    "        spot_numbers = A_F.count_spots(database, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2529e70-1259-402c-b185-872cb6f95b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7803d3-7945-4fd0-9756-a75d73c28a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(250 == spot_numbers['n_spots_below'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05f01dc7-cbb0-4227-8393-442cd8a6ddc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [1, 1, 1],\n",
       "       [0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ski.morphology.octagon(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76d0e429-0a93-4887-af4f-afd9b9d7de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "        large_object = ski.morphology.octagon(1, 1)\n",
    "        image_size = large_object.shape\n",
    "        pil, n_lo = A_F.generate_indices(large_object, image_size, is_mask=True, is_lo=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e095ff39-4fb1-4131-9d7f-9d77ad56abf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4b8d576-c97a-472d-b36e-31f70c7040ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "        assert np.all(np.array([1, 3, 4, 5, 7]) == np.sort(pil[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff09e177-7fc0-4433-9196-8f8c9a10695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['x', 'y', 'sum_intensity_in_photons', 'z', 'image_filename']\n",
    "n_files = 5\n",
    "n_z = 25\n",
    "\n",
    "analysis_data_1 = None\n",
    "for file in np.arange(n_files):\n",
    "    filename = str(file).zfill(4)\n",
    "    for z in np.arange(n_z):\n",
    "        spot_distribution = np.random.randint(size=(1000, 2), low=0, high=1200)\n",
    "        sum_intensity_in_photons = np.ones(len(spot_distribution))\n",
    "        image_filename = np.full(len(sum_intensity_in_photons), filename)\n",
    "        z_data = np.full_like(sum_intensity_in_photons, z)\n",
    "        if analysis_data_1 is not None:\n",
    "                analysis_data_1 = np.hstack([analysis_data_1, np.vstack([spot_distribution.T, sum_intensity_in_photons, z_data, image_filename])])\n",
    "        else:\n",
    "            analysis_data_1 = np.vstack([spot_distribution.T, sum_intensity_in_photons, z_data, image_filename])\n",
    "database = pl.DataFrame(data=analysis_data_1, schema=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1bfba9-50f3-480a-b65a-fb857a30be7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ae5e3e-6782-4f7d-8350-55dc610094f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_F.calculate_rdf_with_thresholds(analysis_data_1=analysis_data_1, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
